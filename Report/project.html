<!DOCTYPE html>
<html>
<head>
<title>Project Report [ece695cps]</title>

<style>
	body {
	    position: relative;
	    width: 1024px;
	    height: 768px;
	    height: 100%;
	    font-family: Calibri, Candara, Segoe, "Segoe UI", Optima, Arial, sans-serif;
	}

	html {
	    display: table;
	    margin: auto;
	}

	body {
	    display: table-cell;
	    vertical-align: middle;
	    text-align: justify;
    	text-justify: inter-word;
	}

	h1 {
		font-size: 26px;
	}
</style>

</head>
<body>

<h1>A Context-Dependent Crowdsourcing Approach for Entity Recognition and Linking on Tweets</h1>
<p><i>This is a course project at Purdue University taught by Prof.Alex Quinn.</i></p>

<h2>Team Members</h2>
Jiawei Zhang (<a href="mailto:zhan1486@purdue.edu">zhan1486@purdue.edu</a>) and Jianqiao Liu (<a href="mailto:liu1274@purdue.edu">liu1274@purdue.edu</a>)

<h2>Introduction</h2>
<p>A named-Entity is a term or a phrase that identifies a real-world object. Typical examples include names of person, organization, location, brand, etc. Named-Entity Recognition has long been a key issue in text mining and natural language processing fields. While existing approaches are proved to be effective in standard text such as published articles and news media, their performance severely degrades on social media text such as tweets, where people tend to use informal grammar and obscure words. To this end, we introduce a crowdsourcing approach toward effective named-entity recognition on tweets. Our approach primarily focuses on entities that are dependent on the contextual information of the tweet or the conversation, as these entities vary across context and are challenging for conventional techniques. Our approach utilizes the automatic linguistic tools to pre-process tweets and extract potential named-entities, and then involves the workers to verify and disambiguate the automatically-generated results through an intelligent visual interactive interface. In the rest of this blog, we discuss related work in terms both automatic and crowdsourcing aspects, describe our techniques in details, and provide a system demo as well as preliminary results.</p>

<!-- <h2>Research Problem</h2>
Recognize named-entity in Twitter messsage. In the project, we specifically focus on three types of named-entities: names of person, organization and location. We focus on three sub-tasks.
<ul>
<li>Identify the word or the phrase that is a named-entity and choose the type of the entity.</li>
<li>Disambiguate an entity by expanding the entity or providing supporting information.</li>
<li>Link entities that refer to the same object.</li>
</ul> -->

<!-- The <a href="http://dx.doi.org/10.1145/368481.368507" title="Donald E. Knuth. 1959. RUNCIBLE—algebraic translation on a limited computer. Commun. ACM 2, 11 (November 1959), 18-21.">Runcible</a> compiler supported algebraic translation on a limited computer. -->

<!-- <a href="http://dx.doi.org/" title=""></a> -->

<h2>Related Work</h2>
<p><a href="http://dx.doi.org/10.1075/li.30.1.03nad" title="Nadeau, David, and Satoshi Sekine. A survey of named entity recognition and classification. Lingvisticae Investigationes 30.1 (2007): 3-26.">Named-Entity Recognition</a> is one of the primary tasks in natural language processing field (NER).
In general, NER extracts structured knowledge from the unstructured text, which can further be utilized as meaningful features for text mining and maching learning.
NER-related research consists of two primary directions: the machine learning paradigm and the human-driven paradigm.
In this section, we provide an overview of the two fields respectively.</p>

The machine learning paradigm mainly consists of supervised approaches and unsupervised approaches.
For supervised approaches, various learning models have been applied to tackle this challenge, examples of which include the <a href="http://dx.doi.org/10.1023/A:1007558221122" title="Bikel, Daniel M., Richard Schwartz, and Ralph M. Weischedel. An algorithm that learns what's in a name. Machine learning 34.1 (1999): 211-231.">Hidden Markov Models</a>, <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.641.2654&rep=rep1&type=pdf" title="Borthwick, Andrew. A maximum entropy approach to named entity recognition. Diss. New York University, 1999.">Maximum Entropy</a>, <a href="http://dx.doi.org/10.3115/1118853.1118873" title="McNamee, Paul, and James Mayfield. Entity extraction without language-specific resources. proceedings of the 6th conference on Natural language learning-Volume 20. Association for Computational Linguistics, 2002.">Support Vector Machine</a>. The core methodology in this category is to define the named-entity recogntion as a classification problem and aim to maximize the probablity based on the training data. Hence, the quantity and quality of the training data influences the accuracy significantly. Since a robust and large traning set requires a large amount of human effort, many text-mining tasks do not have a good annotated corpus available. Hence, much research has been explored that utilized the unsupervised learning methods. Most unsupervised learning approaches are based on the assumption that for many named-entities, both the entity itself and the co-occuring context are consistent across multiple data instances, thus making it possible for the unsupervised algorithms such as data clustering to identify entity patterns. Unsupervised learning approaches are proved to be effective on <a href="http://dl.acm.org/citation.cfm?id=2392777.2392781" title="Munro, Robert, and Christopher D. Manning. Accurate unsupervised joint named-entity extraction from unaligned parallel text. Proceedings of the 4th Named Entity Workshop. Association for Computational Linguistics, 2012.">multiple languages</a> and <a href="http://dx.doi.org/10.1016/j.artint.2005.03.001" title="Etzioni, Oren, et al. Unsupervised named-entity extraction from the web: An experimental study. Artificial intelligence 165.1 (2005): 91-134.">data sources</a>.



<h2> Design</h2>
<p>To address the obscure words problem, we expect a perfect natural language processing (NLP) algorithm that can automatically partition the sentences, extract the tokens, analyze the context and tag the tokens with necessary descriptions. However, in practice, we find that event the state-of-the-art natural language processing algorithms are far away from satisfactory. On one hand, NLP algorithms perform well at “word” level extraction, but fail at understanding and capture words (combinations) that people use for convention or amusement. For example, the NLP would treat the “Hoosiers” as an organization name in the tweet “Indiana fans celebrating the Hoosiers' most recent national championship”. Actually here the “Hoosiers” just means the Indiana state. On the other hand, there are many words created in our culture. Even the normal words we used for a long history may be given new meanings. For example, “The Unburnt Queen of the Andals, Queen of Meereen, Khaleesi of the Great Grass Sea, Breaker of Chains, Mother of Dragons.” It looks like all words here are just normal use, but people who haven’t read/watched the Game of the Throne can hardly understand these words’ real meaning. All these five phrases are the title of Daenerys Targaryen, a key role in the novel/movie.
</p>

<p style="text-align:center;"><img src="resources/workflow.png" alt="interface" style="width:720px;"><br>Fig 1. The workflow of the system</p>

<p>Based on our discovery, we design a crowd sourcing approach to effectively recognize entities in tweets. Our system can not only help people with no background knowledge understand the context more easily, but also help machine learning algorithms learn more effectively. We design our NER is three steps:

<p>1.	Query the user tweets with our crowd knowledge database, and mark all the entities that have already been recognized</p>

<p>2.	Use standard NLTK (Natural Language Toolkit 3.0) to process the tweets. In this process, we ignore the entities marked in the first. And due to the time limitation, we only consider three categories: the person, the organization and the location. </p>

<p>3.	Ask the crowd sourcing to correct the recognition results from previous steps and add entities that have not been recognized. The crowd modified result will be updated into knowledge database.
</p>



<h2>Implementation</h2>
<p style="text-align:center;"><img src="resources/UI.png" alt="interface" style="width:1024px;"><br>Fig 2. The user interface of the system</p>
<p>
Our target is to recognize obscure words in tweets as meaningful entities and link them to some other entities that are easier to understand/track. We organize the whole task with two separate database tables: the NPO table and ETY table.
</p>

<p>
NPO table -- Unique, real record for each natural person/organization/location/others, just like one's legal name. E.g. "Donald Trump". Each record in NPO would store the name, class, description and all records in ETY that are sourced from it. We call each record in NPO table a "SRC".
</p>

<p>
ETY table -- Any entity detected by machine/crowd from tweets, like one's nickname. Usually the mapping from record in ETY to record in NPO is a multiple-to-one mapping. E.g. "45", "DT" and "Orange Julius" could all exist in ETY table, and their "source" point to "Donald Trump" in NPO table. The "Donald Trump" may and may not exist in ETY (depends whether it appear in tweet). We call each record in ETY table a "DES".
</p>

<p>
When the crowd knowledge database detects an entity, the back-end will query the ETY table, and send the context and comment when the link is built to the front end. 
</p>

<p>
When the crowd find a new entity, or correct an existing entity from tweets, they need to specify a NPO name for the entity. If the NPO name could be searched from our NPO table, we will create a new DES in ETY table, and add it into the “destination” of that NPO SRC. Otherwise, we need to create both a DES in ETY table and a SRC in NPO table and link them together. In both conditions, we prefer the workers to add some comments about why they link them and will show the comments when the link is searched in the future.
</p>

<p>
We strongly recommend the worker to use the most widely known name as SRC's name. The SRC's name is the unique keyword we define a person/place/object in our system. For current step, we can not avoid the duplication in NPO by machine, but we may potentially use crowd source to do this in the future. The description of SRC could be a link to a Wikipedia webpage, or a piece of words written by the user.
</p>


<h2>Approach and Implementation</h2>

<p style="text-align:center;"><img src="resources/project.PNG" alt="interface" style="width:720px;"><br>Fig 1. The mock-up interface of the approach.</p>

<b>How to organize data?</b>
<br>
Our system will be based on a client-server architecture. The server captures the real-time Twitter stream based on a user-defined geographical box and send them to the client in real-time. A Twitter message can contain timestamp, user id, user name, geolocation and message content. 
<br>
<br>

<b>What does the UI look like?</b>
<br>
There will be a tabular view to interact with the participants (Fig 1). The content of the tabular view includes a textbox, a table, a “Next” button and an “Update” field:
The textbox shows a tweet assigned to the participant. These entities that have already been recognized by our system will be highlighted.
The table lists every entity recognized in the tweet and these other entities potentially related with it. These “potentially related entities” are extracted from our database.
<br>
<br>
If the participant is satisfied with the automatically generated result, he/she should click the “Next” button and get a new tweet. The result of the old tweet will be confirmed (explained in the question below). 
Otherwise, the participant is asked to filled in the separate “Update” field. The layout of the field is similar to this: Keyword: <i>45</i>; Entity: <i>Trump</i>; Comment: <i>...</i>;  “Update” button.
<br>
<br>

<b>How does the user interact with the system?</b>
<br>
If the participant click the “Next” button, our system will submit the result to our background. All unmodified result will increase its “Strength” attribute by 1. 
If the participant add some new entities and connections, our system will use the time of the tweet, all the entities in the tweet and the comment to create a new entity. The connects are initialized with “Strength = 1”.
<br>
<br>

<b>How to update the data collected from participants?</b>
<br>
Each entity has connections with other entities. These connections are measured by their “Strength” attribute. When the participant agrees with an existing connection, its “Strength” value will be increased and vice versa. The connection will be deleted once its strength drops below some threshold.
In the result page, these connection are shown in the order of their “Strength” value. 
<br>
<br>

<b>How to review the workers' result?</b>
<br>
We provide two different views to show the result. In the tweet-centric view, we list all tweets that have been reviewed and tagged by the workers. For each tweet, we highlight the entities and their types that were edited by the workers. We also show additional entities that are related to the ones in the current tweet in another column.In the entity-centric view, we list all the entities that are recognized by the workers. For each entity, we visualize the different types and their percentage (confidence) using a pie chart. We also show entities relevant to the current one in another column. Finally, we provide user's comment/explanation in an extra column.
<br>
<br>

<b>How to validate the approach?</b>
<br>
We will recruit 5-10 workers to recognize named-entities of real-time Twitter streams from a relative small region, so that the number of tweets won't be so many that would add cognitive overload to the users. The workers will be asked to work collaboratively. Each session will last for 20 minutes. The entities detected by the users will be compared with the automatic approaches.
<br>
<br>

<h2>Evaluation and Results</h2>

<h2>Conclusion</h2>

<h2>Acknowledgements</h2>

<!-- <h2>References</h2>
<ul>
  <li>Zhai, Haijun, et al. "Web 2.0-based crowdsourcing for high-quality gold standard development in clinical natural language processing." Journal of medical Internet research 15.4 (2013): e73.
</li>
  <li>Bontcheva, Kalina, Leon Derczynski, and Ian Roberts. "Crowdsourcing named entity recognition and entity linking corpora." The Handbook of Linguistic Annotation (2014).</li>
  <li>Finin, Tim, et al. "Annotating named entities in Twitter data with crowdsourcing." Proceedings of the NAACL HLT 2010 Workshop on Creating Speech and Language Data with Amazon's Mechanical Turk. Association for Computational Linguistics, 2010.</li>
</ul> -->

</body>
</html>